{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "from html import unescape\n",
    "\n",
    "# patterns in log files\n",
    "incident_pattern = r\"Incident #:\\s*(\\d+)\"\n",
    "date_pattern = r\"Date:\\s*(\\d{4}-\\d{2}-\\d{2}\\s*\\d{2}:\\d{2}:\\d{2})\"\n",
    "type_pattern = r\"Type:\\s*([\\w\\s/]+)\"\n",
    "location_pattern = r\"Location:\\s*(.+?)(?=\\n|$)\"\n",
    "arrest_pattern = r\"Arrested:\"\n",
    "name_pattern = r\"Name:\\s*([^:\\n]+?)(?=\\s*Date of Birth:)\"\n",
    "dob_pattern = r\"Date of Birth:\\s*(\\d{2}/\\d{2}/\\d{4})\"\n",
    "charges_pattern = r\"Charges:\\s*((?:.+?(\\n|$))*?)(?=\\n(?:\\w+:|$))\"\n",
    "\n",
    "# folder pattern (e.g., \"yyyy_law_pd_data\")\n",
    "folder_pattern = re.compile(r\"^\\d{4}_law_pd_data$\")\n",
    "\n",
    "def process_pdf(file_path):\n",
    "    data = []\n",
    "    with pdfplumber.open(file_path) as pdf:\n",
    "        text = \"\\n\".join(page.extract_text() for page in pdf.pages if page.extract_text())\n",
    "        text = unescape(text)\n",
    "\n",
    "        # split incidents on lines \"===========\" (the separator between incidents)\n",
    "        incidents = re.split(r\"={10,}\", text)\n",
    "        for incident in incidents:\n",
    "            incident_number = re.search(incident_pattern, incident)\n",
    "            date = re.search(date_pattern, incident)\n",
    "            type_field = re.search(type_pattern, incident)\n",
    "            location = re.search(location_pattern, incident)\n",
    "\n",
    "            arrested = \"No\"\n",
    "            name = \"\"\n",
    "            dob = \"\"\n",
    "            charges = \"\"\n",
    "\n",
    "            # check if \"Arrested:\" exists\n",
    "            if re.search(arrest_pattern, incident):\n",
    "                arrested = \"Yes\"\n",
    "                name_match = re.search(name_pattern, incident)\n",
    "                dob_match = re.search(dob_pattern, incident)\n",
    "                charges_match = re.search(charges_pattern, incident, re.DOTALL)\n",
    "\n",
    "                name = name_match.group(1).strip() if name_match else \"N/A\"\n",
    "                dob = dob_match.group(1) if dob_match else \"N/A\"\n",
    "                if charges_match:\n",
    "                    # split charges into separate lines and join with \";\"\n",
    "                    charges = \"; \".join(\n",
    "                        line.strip() \n",
    "                        for line in charges_match.group(1).splitlines() \n",
    "                        if line.strip()\n",
    "                    )\n",
    "                else:\n",
    "                    charges = \"N/A\"\n",
    "\n",
    "            # add the row/entry\n",
    "            data.append({\n",
    "                \"Incident #\": incident_number.group(1) if incident_number else \"\",\n",
    "                \"Date\": date.group(1) if date else \"\",\n",
    "                \"Type\": type_field.group(1) if type_field else \"\",\n",
    "                \"Location\": location.group(1) if location else \"\",\n",
    "                \"Arrested\": arrested,\n",
    "                \"Name\": name,\n",
    "                \"DOB\": dob,\n",
    "                \"Charges\": charges\n",
    "            })\n",
    "    return data\n",
    "\n",
    "def process_all_pdfs(root_folder, output_csv):\n",
    "    all_data = []\n",
    "    # walk through every subdirectory in root_folder\n",
    "    for current_path, dirs, files in os.walk(root_folder):\n",
    "        folder_name = os.path.basename(current_path)\n",
    "\n",
    "        # skip folders that don't match the pattern \"yyyy_law_pd_data\"\n",
    "        if not folder_pattern.match(folder_name):\n",
    "            continue\n",
    "\n",
    "        for file in files:\n",
    "            if file.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(current_path, file)\n",
    "                print(f\"Processing: {file_path}\")\n",
    "                all_data.extend(process_pdf(file_path))\n",
    "\n",
    "    # write the combined data to CSV\n",
    "    with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "        fieldnames = [\"Incident #\", \"Date\", \"Type\", \"Location\", \"Arrested\", \"Name\", \"DOB\", \"Charges\"]\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The combined CSV is at: output_all_years.csv\n"
     ]
    }
   ],
   "source": [
    "root_folder = r\"C:\\Users\\Indel\\OneDrive\\Documents\\Data Science RA\\gatewayinitiative-lawrencepd\\data\"\n",
    "output_csv = \"output_all_years.csv\"\n",
    "\n",
    "# recursively process every .pdf under 'data/.../'\n",
    "process_all_pdfs(root_folder, output_csv)\n",
    "\n",
    "print(\"The combined CSV is at:\", output_csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
